{
  "job_name": "reddit_ingest_10k_records",
  "source_type": "api",
  "ingestion_type": "incremental",
  "incremental_column": "after",
  "batch_size": 100,
  "ingestion_status": "active",
  "source_config": {
    "verify_ssl": false,
    "url": "https://www.reddit.com/r/dataengineering/new.json",
    "method": "GET",
    "headers": { 
      "User-Agent": "python:BecaDataPipeline:v1.0 (by /u/mouse_data_eng)" 
    },
    "auth": {
      "type": "bearer",
      "token_env_var": "REDDIT_TOKEN"
    },
    "params": { 
      "limit": 100 
    },
    "data_path": "data.children",
    "pagination": {
      "strategy": "cursor", 
      "cursor_param": "after", 
      "cursor_path": "data.after",
      "max_pages": 100, 
      "sleep_time": 1
    }
  },
  "target": {
    "format": "delta",
    "mode": "append",
    "path": "s3a://raw-data/reddit_posts",
    "primary_key": "data.id",
    "partition_by": ["_ingest_date"],
    "schema_evolution": "merge",
    "transformations": [
      { "type": "add_ingestion_timestamp" }
    ]
  },
  "dag_params": {
    "schedule_interval": "@daily",
    "owner": "data_engine",
    "retries": 3,
    "retry_delay_min": 5,
    "start_date": "2025-01-01",
    "catchup": false
  }
}